# fase6cap1
# Projeto Fase 6 - YOLOv5 (Banana e Garrafa)

Este projeto faz parte da Fase 6 da FIAP, na disciplina de Intelig√™ncia Artificial. O objetivo foi criar um modelo de vis√£o computacional usando o YOLOv5 para identificar dois objetos: **banana** e **garrafa**. 
As imagens foram rotuladas no MakeSense.ai e organizadas em pastas de treino, valida√ß√£o e teste dentro do Google Drive. O trabalho foi feito no Google Colab com integra√ß√£o ao YOLOv5.

Foram realizados dois treinos para compara√ß√£o: um com **30 √©pocas** e outro com **60 √©pocas**. O modelo de 60 √©pocas apresentou melhor desempenho, com mais acertos nas detec√ß√µes e melhor mAP. As imagens de teste mostraram que o YOLOv5 conseguiu identificar corretamente as classes na maioria dos casos.

As etapas principais foram:
1. Montar o Google Drive no Colab.
2. Clonar o reposit√≥rio do YOLOv5 e instalar as depend√™ncias.
3. Executar o treino do modelo com o comando:  
   `python train.py --img 640 --batch 16 --epochs 60 --data /content/drive/MyDrive/dataset_yolo/data.yaml --weights yolov5s.pt`
4. Fazer a infer√™ncia com o modelo treinado para testar nas imagens de `/test`.
5. Comparar os resultados entre os dois treinos.

Mesmo com uma base pequena de imagens (cerca de 80), o modelo teve bom desempenho. Como melhoria, seria interessante aumentar o dataset, aplicar t√©cnicas de data augmentation e testar outras vers√µes do YOLO (como yolov5m ou yolov5l).

üìò Notebook Colab: [Abrir aqui](https://colab.research.google.com/drive/1vCccYQXcjkOQeCdrnp1lhiGr7IvJORoa)  
üé• V√≠deo de demonstra√ß√£o: *(adicionar link do YouTube)*  

Durante os testes realizados com o YOLOv5, foi poss√≠vel observar diferen√ßas claras entre o treino com 30 √©pocas e o treino com 60 √©pocas.  
Os resultados ficaram salvos nas pastas geradas automaticamente pelo YOLOv5:  
`/content/yolov5/runs/detect/expA_test` e `/content/yolov5/runs/detect/expB_test`.

O modelo treinado com **60 √©pocas** apresentou melhor desempenho geral, com maior precis√£o e recall. Ele conseguiu detectar com mais facilidade as **bananas** e as **garrafas**, mesmo quando as imagens tinham varia√ß√µes de ilumina√ß√£o e posi√ß√£o.  
J√° o modelo com **30 √©pocas** foi mais r√°pido para treinar, mas teve alguns erros de detec√ß√£o em imagens mais complexas.

Nos testes de valida√ß√£o, as m√©tricas mostraram uma melhora no **mAP** e na **precis√£o** conforme o n√∫mero de √©pocas aumentou, comprovando que o modelo aprendeu melhor os padr√µes das classes.  
As imagens processadas (armazenadas em `yolov5/runs/detect/expX`) mostram claramente as detec√ß√µes corretas, com caixas delimitando os objetos e o nome da classe identificado.

De forma geral, os resultados foram positivos. Mesmo com um dataset pequeno, o YOLOv5 conseguiu alcan√ßar bons √≠ndices de acerto.  
Como melhorias futuras, seria interessante:
- Aumentar a quantidade e diversidade de imagens no dataset;  
- Aplicar **data augmentation** para melhorar a generaliza√ß√£o;  
- Testar outras arquiteturas do YOLO, como **yolov5m** ou **yolov5l**;  

Em resumo, o projeto atingiu seu objetivo de demonstrar como um modelo de vis√£o computacional pode identificar objetos espec√≠ficos com boa precis√£o, validando o funcionamento pr√°tico da rede neural YOLOv5.

Feito por **Vivian Amorim**  
FIAP ‚Ä¢ Curso de Intelig√™ncia Artificial ‚Ä¢ Fase 6
